{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c78f3a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874db803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7b7c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-10 02:15:38.356884: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-10 02:15:38.375548: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746832538.397174  101790 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746832538.403210  101790 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746832538.420066  101790 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746832538.420115  101790 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746832538.420119  101790 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746832538.420121  101790 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-10 02:15:38.425749: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87686aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (0.22.0)\n",
      "Requirement already satisfied: torchaudio in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from triton==3.3.0->torch) (78.1.1)\n",
      "Requirement already satisfied: numpy in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffdf5eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from triton==3.3.0->torch) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "%pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d1dd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be67ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_name = \"aubmindlab/aragpt2-base\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38675a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(file_path, tokenizer, block_size=128):\n",
    "    return TextDataset(\n",
    "        tokenizer=tokenizer,\n",
    "        file_path=file_path,\n",
    "        block_size=block_size\n",
    "    )\n",
    "\n",
    "train_dataset = load_dataset(\"/home/doaa/programming/NLP/preprocessed_arwiki_for_autocomplete.txt\", tokenizer)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d82cb27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers[torch]) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers[torch]) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers[torch]) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers[torch]) (2.7.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from transformers[torch]) (1.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (1.1.0)\n",
      "Requirement already satisfied: psutil in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from torch>=2.0->transformers[torch]) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from triton==3.3.0->torch>=2.0->transformers[torch]) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers[torch]) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages (from requests->transformers[torch]) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5b0dead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: accelerate\n",
      "Version: 1.6.0\n",
      "Summary: Accelerate\n",
      "Home-page: https://github.com/huggingface/accelerate\n",
      "Author: The HuggingFace team\n",
      "Author-email: zach.mueller@huggingface.co\n",
      "License: Apache\n",
      "Location: /home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages\n",
      "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd19ed43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12837' max='14844' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12837/14844 21:07:28 < 3:18:11, 0.17 it/s, Epoch 2.59/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>7.630900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>6.765300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>6.397700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>6.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>6.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.868000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>5.867700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>5.801100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>5.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>5.688600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>5.589200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>5.580800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>5.575800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>5.526800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>5.544400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>5.523600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>5.463900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>5.417800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>5.474900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>5.400500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>5.434800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>5.264700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>5.346200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>5.392200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>5.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>5.341700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>5.262800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>5.316100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>5.265400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>5.299300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>5.204600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>5.262400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>5.243500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>5.269900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>5.200100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>5.285900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>5.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>5.250400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>5.204000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>5.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>5.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>5.177200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>5.185100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>5.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>5.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>5.169600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.993200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>4.919200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>4.938900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>4.906600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>4.896100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>4.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>5.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>4.858000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>4.907000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>4.918300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>4.929500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>4.876300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>4.928200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>4.864100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>4.878700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>4.901900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>4.941800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>4.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>4.859200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.945400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>4.933900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>4.869900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>4.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>4.862000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>4.876200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>4.808800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>4.899500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>4.847300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>4.871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.805600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>4.782100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>4.798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>4.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>4.794300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>4.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>4.799000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>4.899400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>4.850200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>4.869600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>4.707300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>4.818800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>4.841500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>4.817200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>4.834900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>4.855700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>4.800600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>4.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>4.831500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>4.808400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>4.739800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>4.567100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>4.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>4.686200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>4.625200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>4.670900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>4.590300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>4.720500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>4.626900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>4.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>4.631500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>4.694800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>4.663200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>4.651200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>4.629800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>4.626600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>4.676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>4.596500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>4.641400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>4.629700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>4.566500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>4.669400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>4.599900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>4.617400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>4.637900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>4.611900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>4.676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>4.647700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>4.584100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/doaa/miniconda3/envs/onnxenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./aragpt2-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100,\n",
    "    prediction_loss_only=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea0ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
